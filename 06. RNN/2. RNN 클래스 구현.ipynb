{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 개념 정리\n",
    "\n",
    "###### (1) 클래스: 제품의 설계도 (신발 설계도)\n",
    "###### (2) 객체: 설계도로 만든 제품 (빨간 신발, 파란 신발 등)\n",
    "###### (3) 속성: 클래스안의 변수\n",
    "###### (4) 메서드: 클래스 안의 함수\n",
    "###### (5) 생성자: 객체를 만들 때 실행되는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. MyRNNcell 클래스 구현하기 - init 함수 구현\n",
    "###### [1] nn.Module을 상속하여 SimpleRNN 클래스를 정의\n",
    "###### [2] SimpleRNN 클래스 생성시 입력 크기(input_size), 은닉상태크기(hidden_size), 출력벡터크기(output_size)를 매개 변수로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# nn.Module은 신경망 모델의 기본 구조를 정의해주는 부모 클래스\n",
    "# nn.Module(부모클래스)을 상속박아 MyRNNcell(자식클래스)를 정의\n",
    "class MyRNNcell(nn.Module):\n",
    "    \n",
    "    # 클래스의 초기화 메서드(객체가 만들어질 때, 자동으로 호출되는 메서드)\n",
    "    # input_size(입력 벡터의 크기), hidden_size(은닉 상태 벡터의 크기)\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "\n",
    "        # 부모 클래스(nn.Module)에서 설정된 기능을 호출\n",
    "        super(MyRNNcell, self).__init__()\n",
    "\n",
    "        # hidden_size(은닉 상태) 크기를 설정\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # 입력 가중치 초기화\n",
    "        # nn.Parameter는 신경망 모델의 학습 가능한 매개변수를 정의할 때 사용하는 텐서\n",
    "        # torch.randn는 주어진 크기로 텐서를 생성하며, 평균0, 표준편차1인 정규분포를 따름\n",
    "        self.Wx = nn.Parameter(torch.randn(hidden_size, input_size))\n",
    "\n",
    "        # 은닉 상태 가중치 초기화\n",
    "        # 이전 은닉 상태와 곱할 가중치 설정 (hidden_size x hidden_size 크기를 가짐)\n",
    "        self.Wh = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        # 편향 벡터 초기화\n",
    "        self.b = nn.Parameter(torch.randn(hidden_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. MyRNNcell 클래스 구현하기 - forward 함수 구현\n",
    "###### [1] forward 함수는 PyTorch에서 순전파를 정의하는 함수 즉 입력 데이터를 받아서 출력으로 변환하는 과정을 정의\n",
    "###### [2] forward 함수는 현재 입력과 이전 은닉 상태를 받아서 새로운 은닉 상태를 계산하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init 함수 구현\n",
    "class MyRNNcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MyRNNcell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.Wx = nn.Parameter(torch.randn(hidden_size, input_size))\n",
    "        self.Wh = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "        self.b = nn.Parameter(torch.randn(hidden_size))\n",
    "\n",
    "    # forward 함수 구현\n",
    "    # forward 함수는 x(입력 벡터)와 hidden(이전 은닉 상태 벡터)을 입력값으로 받는다\n",
    "    def forward(self, x, hidden):\n",
    "\n",
    "        # 새로운 은닉 상태 계산\n",
    "        # (1) x와 Wx의 전치(행렬의 행과 열을 바꾸는 연산)를 곱하기 - 차원을 맞추기 위해 사용\n",
    "        hidden = torch.tanh(torch.matmul(x, self.Wx.t()) \n",
    "                        \n",
    "                        # hidden(이전은닉상태)와 Wh(은닉상태가중치)의 전치를 곱하기\n",
    "                        + torch.matmul(hidden, self.Wh.t()) \n",
    "\n",
    "                        # b(편향을 더하기)\n",
    "                        + self.b)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. MyRNNcell 인스턴스(객체)를 통한 새로운 은닉 상태 계산\n",
    "###### [1] MyRNNcell을 사용해서 새 은닉 상태 계산하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 은닉 상태 tensor([[-0.0175, -0.8680,  0.7162,  0.6077, -0.9997, -0.4917]],\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_rnn = MyRNNcell(4,6)\n",
    "\n",
    " # 랜덤 시드를 설정하여 무작위 숫자가 생성될 때마다 동일한 결과를 얻도록 설정\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 랜덤 Xt(입력데이터) 생성 (input_size = 4)\n",
    "Xt = torch.randn(1,4)\n",
    "\n",
    "# ht-1(초기은닉상태) 생성 (hidden_size = 6)\n",
    "ht_1 = torch.zeros(1,6)\n",
    "\n",
    "# 모델 실행 (새로운 ht 생성 공식 적용)\n",
    "ht = model_rnn(Xt, ht_1)\n",
    "print(\"새로운 은닉 상태\", ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 시퀀스 데이터 처리를 위한 MyRNN 클래스 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. __init__ 함수 구현\n",
    "###### MyRNN 클래스를 사용하여 RNN cell의 동작을 정의하고, 이를 MyRNN 클래스에 내장하여 전체 시퀀스를 처리하는 MyRNN 클래스를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyRNN 클래스 생성 이는 nn.Module을 상속받음\n",
    "class MyRNN(nn.Module):\n",
    "\n",
    "    # 초기화 메서드를 정의\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \n",
    "        # 부모 클래스인 nn.Module의 초기화 메서드를 호출\n",
    "        super(MyRNN, self).__init__()\n",
    "\n",
    "        # 은닉 상태 크기 설정\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # RNN의 계산 단위 담당: 입력 벡터와 이전 은닉 상태를 받아 최종 출력을 계산\n",
    "        self.rnn_cell = MyRNNcell(input_size, hidden_size)\n",
    "\n",
    "        # 출력 가중치 행렬 정의\n",
    "        self.Wy = nn.Parameter(torch.randn(output_size, hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. init_hidden 함수 내부 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyRNN 클래스: init 함수 구현\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn_cell = MyRNNcell(input_size, hidden_size)\n",
    "        self.Wy = nn.Parameter(torch.randn(output_size, hidden_size)) \n",
    "\n",
    "################################# 위와 동일 #######################################\n",
    "\n",
    "    # 초기 은닉상태 인스턴스 생성 - 초기값이기에 아무것도 없어 0으로 초기화\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-3. forward 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyRNN 클래스 정의\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn_cell = MyRNNcell(input_size, hidden_size)\n",
    "        self.Wy = nn.Parameter(torch.randn(output_size, hidden_size))\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "################################# 위와 동일 #######################################\n",
    "\n",
    "    # forward 함수 정의 - x는 입력 데이터\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 은닉상태의 크기 정의 - 입력데이터의 batch size와 동일\n",
    "        ht = self.init_hidden(x.size(0))\n",
    "        \n",
    "        # \n",
    "        for i in range(x.size(1)):\n",
    "            ht = self.rnn_cell(x[:, i], ht)\n",
    "        \n",
    "        output = torch.sigmoid(torch.matmul(ht, self.Wy.t()))  # Sigmoid activation\n",
    "        return output, ht"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
